CONTEXT_LENGTH = 7000 # for Qwen32B to fit
MAX_NUM_BATCHED_TOKENS = 4096
BLOCK_SIZE = 16
GPU_MEM_UTIL = 0.9
MODES = ["train", "test"]
MAX_NUM_SEQS = 4096
SEED = 42
GPU_TYPE = "NVIDIA-H100-80GB-HBM3"
GPU_MEMORY_MIN = 50000
NAMESPACE = "blis"
CHUNK_SIZES = [256, 2048]
NUM_PROMPTS = 2000
REQUEST_RATES = [5]
PREFIX_HIT_RATIOS = [0.3, 0.6]
DATASET_PATH = "ShareGPT_V3_unfiltered_cleaned_split.json"
MODEL = "Qwen/Qwen3-14B"
SPECS = ["LL"]
TOTAL_KV_BLOCKS = {
    "Qwen3-14B": 14508,
    "Qwen2_5-7B": 56990
}
QUEUING_DELAYS = {
    "Qwen3-14B-LL": 5612,
    "Qwen3-14B-LH": 13859,
    "Qwen2_5-7B-LL": 4294,
    "Qwen2_5-7B-LH": 8095
}
FINISHED_DELAYS = {
    "Qwen3-14B-LL": 582,
    "Qwen3-14B-LH": 2149,
    "Qwen2_5-7B-LL": 518,
    "Qwen2_5-7B-LH": 935
}

REGRESSION_COEFFS = {
    "Qwen3-14B": [1.17167255e-02, 1.69822525e-05, 1.86698155e-04],
    "Qwen2_5-7B": [6.59619835e-03, 8.13333252e-06, 4.11493210e-05]
}
LL_SPECS = {
    "TYPE": "LL",
    "INPUT_LEN_MIN": 2,
    "INPUT_LEN_MAX": 512,
    "OUTPUT_LEN_MIN": 1,
    "OUTPUT_LEN_MAX": 10
}
LH_SPECS = {
    "TYPE": "LH",
    "INPUT_LEN_MIN": 2,
    "INPUT_LEN_MAX": 512,
    "OUTPUT_LEN_MIN": 100,
    "OUTPUT_LEN_MAX": 2000
}
HL_SPECS = {
    "TYPE": "HL",
    "INPUT_LEN_MIN": 512,
    "INPUT_LEN_MAX": 8000,
    "OUTPUT_LEN_MIN": 1,
    "OUTPUT_LEN_MAX": 10
}
HH_SPECS = {
    "TYPE": "HH",
    "INPUT_LEN_MIN": 512,
    "INPUT_LEN_MAX": 8000,
    "OUTPUT_LEN_MIN": 100,
    "OUTPUT_LEN_MAX": 2000
}