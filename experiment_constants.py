# Experiment Constants - Generated by Streamlit App

BETA_COEFFS = {'Qwen3-14B': [0.0112964994, 3.56589617e-05, 7.48558631e-05], 'Qwen2_5-7B': [0.00659619835, 8.13333252e-06, 4.1149321e-05]}
BLOCK_SIZE = 16
CHUNK_SIZES = [256, 2048]
CONTEXT_LENGTH = 7000
DATASET_PATH = "ShareGPT_V3_unfiltered_cleaned_split.json"
FINISHED_COEFFS = {'Qwen2_5-7B': [0.288576689, 625.360201], 'Qwen3-14B': [1.03981306, 796.73460409]}
GPU_MEMORY_MIN = 50000
GPU_MEM_UTIL = 0.9
GPU_TYPE = "NVIDIA-H100-80GB-HBM3"
HH_SPECS = {'TYPE': 'HH', 'INPUT_LEN_MIN': 512, 'INPUT_LEN_MAX': 8000, 'OUTPUT_LEN_MIN': 100, 'OUTPUT_LEN_MAX': 2000}
HL_SPECS = {'TYPE': 'HL', 'INPUT_LEN_MIN': 512, 'INPUT_LEN_MAX': 8000, 'OUTPUT_LEN_MIN': 1, 'OUTPUT_LEN_MAX': 10}
INFERENCE_SPECS = {'INPUT_LEN_MEAN': 3096, 'OUTPUT_LEN_MEAN': 32}
LH_SPECS = {'TYPE': 'LH', 'INPUT_LEN_MIN': 2, 'INPUT_LEN_MAX': 512, 'OUTPUT_LEN_MIN': 100, 'OUTPUT_LEN_MAX': 2000}
LL_SPECS = {'TYPE': 'LL', 'INPUT_LEN_MIN': 2, 'INPUT_LEN_MAX': 512, 'OUTPUT_LEN_MIN': 1, 'OUTPUT_LEN_MAX': 10}
MAX_NUM_BATCHED_TOKENS = 4096
MAX_NUM_SEQS = 4096
MODEL = "Qwen/Qwen2.5-7B"
MODES = ['train', 'test']
NAMESPACE = "blis"
NUM_PROMPTS = 2000
PREFIX_HIT_RATIOS = [0.05]
QUEUING_COEFFS = {'Qwen2_5-7B': [2.66696657, 5528.8144], 'Qwen3-14B': [2.40788681, 9089.91938]}
REQUEST_RATES = [5]
SEED = 42
SPECS = ['LL', 'LH']
TOTAL_KV_BLOCKS = {'Qwen3-14B': 14508, 'Qwen2_5-7B': 56990}
