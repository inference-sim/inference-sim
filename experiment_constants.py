CONTEXT_LENGTH = 7000 # for Qwen32B to fit
MAX_NUM_BATCHED_TOKENS = 4096
BLOCK_SIZE = 16
GPU_MEM_UTIL = 0.9
MODES = ["train", "test"]
MAX_NUM_SEQS = 4096
SEED = 42
GPU_TYPE = "NVIDIA-H100-80GB-HBM3"
GPU_MEMORY_MIN = 50000
NAMESPACE = "blis"
CHUNK_SIZES = [256, 2048]
NUM_PROMPTS = 2000
REQUEST_RATES = [5]
PREFIX_HIT_RATIOS = [0.3, 0.6]
DATASET_PATH = "ShareGPT_V3_unfiltered_cleaned_split.json"
MODEL = "Qwen/Qwen3-14B"
SPECS = ["LL", "LH"]
TOTAL_KV_BLOCKS = {
    "Qwen3-14B": 14508,
    "Qwen2_5-7B": 56990
}
# QUEUING_DELAYS = {
#     "Qwen3-14B-LL": 5612,
#     "Qwen3-14B-LH": 13859,
#     "Qwen2_5-7B-LL": 4294,
#     "Qwen2_5-7B-LH": 8095
# }
# FINISHED_DELAYS = {
#     "Qwen3-14B-LL": 582,
#     "Qwen3-14B-LH": 2149,
#     "Qwen2_5-7B-LL": 518,
#     "Qwen2_5-7B-LH": 935
# }

QUEUING_COEFFS = {
    "Qwen2_5-7B": [2.66696657e+00, 5.52881440e+03],
    "Qwen3-14B": [2.40788681e+00, 9.08991938e+03]
}

FINISHED_COEFFS = {
    "Qwen2_5-7B": [2.88576689e-01, 6.25360201e+02],
    "Qwen3-14B": [1.03981306, 796.73460409]
}

BETA_COEFFS = {
    "Qwen3-14B": [1.12964994e-02, 3.56589617e-05,7.48558631e-05],
    "Qwen2_5-7B": [6.59619835e-03, 8.13333252e-06, 4.11493210e-05]
}
LL_SPECS = {
    "TYPE": "LL",
    "INPUT_LEN_MIN": 2,
    "INPUT_LEN_MAX": 512,
    "OUTPUT_LEN_MIN": 1,
    "OUTPUT_LEN_MAX": 10
}
LH_SPECS = {
    "TYPE": "LH",
    "INPUT_LEN_MIN": 2,
    "INPUT_LEN_MAX": 512,
    "OUTPUT_LEN_MIN": 100,
    "OUTPUT_LEN_MAX": 2000
}
HL_SPECS = {
    "TYPE": "HL",
    "INPUT_LEN_MIN": 512,
    "INPUT_LEN_MAX": 8000,
    "OUTPUT_LEN_MIN": 1,
    "OUTPUT_LEN_MAX": 10
}
HH_SPECS = {
    "TYPE": "HH",
    "INPUT_LEN_MIN": 512,
    "INPUT_LEN_MAX": 8000,
    "OUTPUT_LEN_MIN": 100,
    "OUTPUT_LEN_MAX": 2000
}

INFERENCE_SPECS = {
    "INPUT_LEN_MEAN": 1000,
    "OUTPUT_LEN_MEAN": 500,
}