2026-01-20 07:24:11,577 INFO vllm.platforms: Automatically detected platform cuda.
2026-01-20 07:24:17,267 INFO vllm.entrypoints.openai.api_server: vLLM API server version 0.11.0
2026-01-20 07:24:17,269 INFO vllm.entrypoints.utils: non-default args: {'model_tag': '/model-cache/models/codellama/CodeLlama-34b-Instruct-hf', 'model': '/model-cache/models/codellama/CodeLlama-34b-Instruct-hf', 'max_model_len': 8192, 'served_model_name': ['codellama/CodeLlama-34b-Instruct-hf'], 'otlp_traces_endpoint': 'http://otel-jan20-codellama-train-1:4318/v1/traces', 'max_num_batched_tokens': 4096, 'max_num_seqs': 256}
2026-01-20 07:24:19,249 INFO vllm.platforms: Automatically detected platform cuda.
2026-01-20 07:24:22,536 INFO vllm.config.model: Resolved architecture: LlamaForCausalLM
2026-01-20 07:24:22,536 INFO vllm.config.model: Using max model len 8192
2026-01-20 07:24:22,817 INFO vllm.config.scheduler: Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-01-20 07:24:25,062 INFO vllm.platforms: Automatically detected platform cuda.
2026-01-20 07:24:27,720 INFO vllm.v1.engine.core: Waiting for init message from front-end.
2026-01-20 07:24:27,728 INFO vllm.v1.engine.core: Initializing a V1 LLM engine (v0.11.0) with config: model='/model-cache/models/codellama/CodeLlama-34b-Instruct-hf', speculative_config=None, tokenizer='/model-cache/models/codellama/CodeLlama-34b-Instruct-hf', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint='http://otel-jan20-codellama-train-1:4318/v1/traces', collect_detailed_traces=None), seed=0, served_model_name=codellama/CodeLlama-34b-Instruct-hf, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention","vllm.sparse_attn_indexer"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":[2,1],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
2026-01-20 07:24:29,358 INFO vllm.distributed.parallel_state: rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
2026-01-20 07:24:29,535 INFO vllm.v1.sample.ops.topk_topp_sampler: Using FlashInfer for top-p & top-k sampling.
2026-01-20 07:24:29,583 INFO vllm.v1.worker.gpu_model_runner: Starting to load model /model-cache/models/codellama/CodeLlama-34b-Instruct-hf...
2026-01-20 07:24:29,714 INFO vllm.v1.worker.gpu_model_runner: Loading model from scratch...
2026-01-20 07:24:29,772 INFO vllm.platforms.cuda: Using Flash Attention backend on V1 engine.
2026-01-20 07:24:57,995 INFO vllm.model_executor.model_loader.default_loader: Loading weights took 28.09 seconds
2026-01-20 07:24:58,351 INFO vllm.v1.worker.gpu_model_runner: Model loading took 62.8571 GiB and 28.287245 seconds
2026-01-20 07:25:03,364 INFO vllm.compilation.backends: Using cache directory: /root/.cache/vllm/torch_compile_cache/3357a83840/rank_0_0/backbone for vLLM's torch.compile
2026-01-20 07:25:03,364 INFO vllm.compilation.backends: Dynamo bytecode transform time: 4.86 s
2026-01-20 07:25:05,181 INFO vllm.compilation.backends: Cache the graph for dynamic shape for later use
2026-01-20 07:25:20,003 INFO vllm.compilation.backends: Compiling a graph for dynamic shape takes 16.37 s
2026-01-20 07:25:26,394 INFO vllm.compilation.monitor: torch.compile takes 21.23 s in total
2026-01-20 07:25:27,073 INFO vllm.v1.worker.gpu_worker: Available KV cache memory: 7.43 GiB
2026-01-20 07:25:27,303 INFO vllm.v1.core.kv_cache_utils: GPU KV cache size: 40,592 tokens
2026-01-20 07:25:27,303 INFO vllm.v1.core.kv_cache_utils: Maximum concurrency for 8,192 tokens per request: 4.96x
2026-01-20 07:25:33,983 INFO vllm.v1.worker.gpu_model_runner: Graph capturing finished in 6 secs, took 0.03 GiB
2026-01-20 07:25:34,014 INFO vllm.v1.engine.core: init engine (profile, create kv cache, warmup model) took 35.66 seconds
2026-01-20 07:25:34,283 INFO vllm.v1.metrics.loggers: Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 2537
2026-01-20 07:25:34,408 INFO vllm.entrypoints.openai.api_server: Supported_tasks: ['generate']
2026-01-20 07:25:34,410 INFO vllm.entrypoints.openai.api_server: Starting vLLM API server 0 on http://0.0.0.0:8000
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Available routes are:
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /openapi.json, Methods: HEAD, GET
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /docs, Methods: HEAD, GET
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /docs/oauth2-redirect, Methods: HEAD, GET
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /redoc, Methods: HEAD, GET
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /health, Methods: GET
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /load, Methods: GET
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /ping, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /ping, Methods: GET
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /tokenize, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /detokenize, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /v1/models, Methods: GET
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /version, Methods: GET
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /v1/responses, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /v1/responses/{response_id}, Methods: GET
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /v1/responses/{response_id}/cancel, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /v1/chat/completions, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /v1/completions, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /v1/embeddings, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /pooling, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /classify, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /score, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /v1/score, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /v1/audio/transcriptions, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /v1/audio/translations, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /rerank, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /v1/rerank, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /v2/rerank, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /scale_elastic_ep, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /is_scaling_elastic_ep, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /invocations, Methods: POST
2026-01-20 07:25:34,410 INFO vllm.entrypoints.launcher: Route: /metrics, Methods: GET
2026-01-20 07:26:34,658 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 314.0 tokens/s, Avg generation throughput: 2.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 7.8%, Prefix cache hit rate: 0.0%
2026-01-20 07:26:44,659 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.8%, Prefix cache hit rate: 0.0%
2026-01-20 07:26:54,659 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.7%, Prefix cache hit rate: 0.0%
2026-01-20 07:27:04,659 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 306.8 tokens/s, Avg generation throughput: 37.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 7.9%, Prefix cache hit rate: 0.0%
2026-01-20 07:27:14,659 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.9%, Prefix cache hit rate: 0.0%
2026-01-20 07:27:24,660 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.8%, Prefix cache hit rate: 0.0%
2026-01-20 07:27:34,661 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 322.2 tokens/s, Avg generation throughput: 37.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.7%, Prefix cache hit rate: 0.0%
2026-01-20 07:27:44,661 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.6%, Prefix cache hit rate: 0.0%
2026-01-20 07:27:54,661 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 525.5 tokens/s, Avg generation throughput: 36.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 13.0%, Prefix cache hit rate: 0.0%
2026-01-20 07:28:04,661 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 14.0%, Prefix cache hit rate: 0.0%
2026-01-20 07:28:14,662 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 14.9%, Prefix cache hit rate: 0.0%
2026-01-20 07:28:24,662 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 318.1 tokens/s, Avg generation throughput: 37.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.2%, Prefix cache hit rate: 0.0%
2026-01-20 07:28:34,662 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 433.1 tokens/s, Avg generation throughput: 36.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 11.0%, Prefix cache hit rate: 0.0%
2026-01-20 07:28:44,662 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 283.2 tokens/s, Avg generation throughput: 37.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 7.6%, Prefix cache hit rate: 0.0%
2026-01-20 07:28:54,663 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.6%, Prefix cache hit rate: 0.0%
2026-01-20 07:29:04,663 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 295.8 tokens/s, Avg generation throughput: 37.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 7.4%, Prefix cache hit rate: 0.0%
2026-01-20 07:29:14,663 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.3%, Prefix cache hit rate: 0.0%
2026-01-20 07:29:24,664 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.3%, Prefix cache hit rate: 0.0%
2026-01-20 07:29:34,665 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 379.0 tokens/s, Avg generation throughput: 36.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.7%, Prefix cache hit rate: 0.0%
2026-01-20 07:29:44,665 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 10.6%, Prefix cache hit rate: 0.0%
2026-01-20 07:29:54,665 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 408.1 tokens/s, Avg generation throughput: 36.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 10.2%, Prefix cache hit rate: 0.0%
2026-01-20 07:30:04,665 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 640.9 tokens/s, Avg generation throughput: 35.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.5%, Prefix cache hit rate: 0.0%
2026-01-20 07:30:14,665 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 17.4%, Prefix cache hit rate: 0.0%
2026-01-20 07:30:24,665 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 37.4 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
2026-01-20 07:30:34,665 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 891.8 tokens/s, Avg generation throughput: 35.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 10.2%, Prefix cache hit rate: 0.0%
2026-01-20 07:30:44,665 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 165.4 tokens/s, Avg generation throughput: 37.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 4.5%, Prefix cache hit rate: 0.0%
2026-01-20 07:30:54,667 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 96.3 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.5%, Prefix cache hit rate: 0.0%
2026-01-20 07:31:04,667 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.5%, Prefix cache hit rate: 0.0%
2026-01-20 07:31:14,667 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 4.4%, Prefix cache hit rate: 0.0%
2026-01-20 07:31:24,667 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 411.6 tokens/s, Avg generation throughput: 36.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 10.8%, Prefix cache hit rate: 0.0%
2026-01-20 07:31:34,668 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 11.8%, Prefix cache hit rate: 0.0%
2026-01-20 07:31:44,668 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
2026-01-20 07:31:54,669 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1038.1 tokens/s, Avg generation throughput: 34.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.6%, Prefix cache hit rate: 0.0%
2026-01-20 07:32:04,670 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 323.4 tokens/s, Avg generation throughput: 37.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.0%, Prefix cache hit rate: 0.0%
2026-01-20 07:32:14,670 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.0%, Prefix cache hit rate: 0.0%
2026-01-20 07:32:24,670 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.9%, Prefix cache hit rate: 0.0%
2026-01-20 07:32:34,670 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 482.9 tokens/s, Avg generation throughput: 36.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 12.4%, Prefix cache hit rate: 0.0%
2026-01-20 07:32:44,672 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 271.9 tokens/s, Avg generation throughput: 37.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 7.6%, Prefix cache hit rate: 0.0%
2026-01-20 07:32:54,672 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.6%, Prefix cache hit rate: 0.0%
2026-01-20 07:33:04,673 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1040.9 tokens/s, Avg generation throughput: 34.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 14.2%, Prefix cache hit rate: 0.0%
2026-01-20 07:33:14,673 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 2459.9 tokens/s, Avg generation throughput: 11.0 tokens/s, Running: 7 reqs, Waiting: 15 reqs, GPU KV cache usage: 70.8%, Prefix cache hit rate: 0.0%
2026-01-20 07:33:24,673 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1441.1 tokens/s, Avg generation throughput: 280.0 tokens/s, Running: 9 reqs, Waiting: 12 reqs, GPU KV cache usage: 84.9%, Prefix cache hit rate: 26.6%
2026-01-20 07:33:34,673 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 929.4 tokens/s, Avg generation throughput: 295.4 tokens/s, Running: 10 reqs, Waiting: 10 reqs, GPU KV cache usage: 99.7%, Prefix cache hit rate: 33.6%
2026-01-20 07:33:44,673 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 620.2 tokens/s, Avg generation throughput: 285.6 tokens/s, Running: 9 reqs, Waiting: 8 reqs, GPU KV cache usage: 99.9%, Prefix cache hit rate: 32.1%
2026-01-20 07:33:54,674 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 2145.2 tokens/s, Avg generation throughput: 259.9 tokens/s, Running: 11 reqs, Waiting: 0 reqs, GPU KV cache usage: 97.5%, Prefix cache hit rate: 40.6%
2026-01-20 07:34:04,675 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 328.3 tokens/s, Running: 8 reqs, Waiting: 0 reqs, GPU KV cache usage: 68.6%, Prefix cache hit rate: 40.6%
2026-01-20 07:34:14,675 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 218.1 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 43.3%, Prefix cache hit rate: 40.6%
2026-01-20 07:34:24,675 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 49.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 40.6%
2026-01-20 07:34:34,675 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 40.6%
2026-01-20 07:34:44,675 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 526.2 tokens/s, Avg generation throughput: 34.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 13.8%, Prefix cache hit rate: 40.5%
2026-01-20 07:34:54,676 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 231.2 tokens/s, Avg generation throughput: 64.8 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 21.1%, Prefix cache hit rate: 40.4%
2026-01-20 07:35:04,676 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 374.7 tokens/s, Avg generation throughput: 86.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 17.0%, Prefix cache hit rate: 40.3%
2026-01-20 07:35:14,676 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 87.8 tokens/s, Avg generation throughput: 87.8 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 21.3%, Prefix cache hit rate: 40.3%
2026-01-20 07:35:24,676 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 450.9 tokens/s, Avg generation throughput: 58.5 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 14.6%, Prefix cache hit rate: 40.2%
2026-01-20 07:35:34,676 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 61.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 12.1%, Prefix cache hit rate: 40.2%
2026-01-20 07:35:44,677 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 372.2 tokens/s, Avg generation throughput: 70.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 23.1%, Prefix cache hit rate: 40.1%
2026-01-20 07:35:54,677 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 519.8 tokens/s, Avg generation throughput: 84.8 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 24.3%, Prefix cache hit rate: 40.0%
2026-01-20 07:36:04,677 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 359.4 tokens/s, Avg generation throughput: 87.2 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 23.6%, Prefix cache hit rate: 39.9%
2026-01-20 07:36:14,677 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 410.0 tokens/s, Avg generation throughput: 81.9 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 35.8%, Prefix cache hit rate: 39.8%
2026-01-20 07:36:24,677 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 166.0 tokens/s, Avg generation throughput: 78.5 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.5%, Prefix cache hit rate: 39.8%
2026-01-20 07:36:34,677 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 74.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 5.1%, Prefix cache hit rate: 39.8%
2026-01-20 07:36:44,679 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 259.7 tokens/s, Avg generation throughput: 70.1 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 13.2%, Prefix cache hit rate: 39.7%
2026-01-20 07:36:54,680 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 600.0 tokens/s, Avg generation throughput: 83.1 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 23.5%, Prefix cache hit rate: 39.6%
2026-01-20 07:37:04,680 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 142.8 tokens/s, Avg generation throughput: 88.7 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 20.3%, Prefix cache hit rate: 39.5%
2026-01-20 07:37:14,680 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 716.8 tokens/s, Avg generation throughput: 70.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 35.0%, Prefix cache hit rate: 39.4%
2026-01-20 07:37:24,681 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 516.1 tokens/s, Avg generation throughput: 43.1 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 31.5%, Prefix cache hit rate: 39.3%
2026-01-20 07:37:34,681 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 74.8 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 33.3%, Prefix cache hit rate: 39.3%
2026-01-20 07:37:44,682 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 563.9 tokens/s, Avg generation throughput: 48.8 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 39.2%
2026-01-20 07:37:54,684 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 324.6 tokens/s, Avg generation throughput: 23.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.6%, Prefix cache hit rate: 39.2%
2026-01-20 07:38:04,685 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 716.7 tokens/s, Avg generation throughput: 48.7 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 27.5%, Prefix cache hit rate: 39.0%
2026-01-20 07:38:14,685 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 269.9 tokens/s, Avg generation throughput: 80.8 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 36.2%, Prefix cache hit rate: 39.0%
2026-01-20 07:38:24,686 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 268.1 tokens/s, Avg generation throughput: 73.8 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 34.2%, Prefix cache hit rate: 38.9%
2026-01-20 07:38:34,686 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 86.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 7.6%, Prefix cache hit rate: 38.9%
2026-01-20 07:38:44,687 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 450.8 tokens/s, Avg generation throughput: 65.5 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 20.3%, Prefix cache hit rate: 38.8%
2026-01-20 07:38:54,688 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 397.5 tokens/s, Avg generation throughput: 44.4 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 38.7%
2026-01-20 07:39:04,690 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 465.3 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 11.8%, Prefix cache hit rate: 38.6%
2026-01-20 07:39:14,691 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 319.5 tokens/s, Avg generation throughput: 43.3 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 20.8%, Prefix cache hit rate: 38.6%
2026-01-20 07:39:24,691 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 75.6 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 22.7%, Prefix cache hit rate: 38.6%
2026-01-20 07:39:34,692 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 47.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.9%, Prefix cache hit rate: 38.6%
2026-01-20 07:39:44,692 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 20.1 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 38.6%
2026-01-20 07:39:54,692 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 14.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 38.5%
2026-01-20 07:40:04,692 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 461.9 tokens/s, Avg generation throughput: 52.1 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 13.7%, Prefix cache hit rate: 38.4%
2026-01-20 07:40:14,692 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 310.4 tokens/s, Avg generation throughput: 36.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.1%, Prefix cache hit rate: 38.4%
2026-01-20 07:40:24,692 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 383.5 tokens/s, Avg generation throughput: 57.5 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 19.0%, Prefix cache hit rate: 38.3%
2026-01-20 07:40:34,692 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 636.6 tokens/s, Avg generation throughput: 91.9 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 37.0%, Prefix cache hit rate: 38.2%
2026-01-20 07:40:44,692 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 335.9 tokens/s, Avg generation throughput: 95.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.9%, Prefix cache hit rate: 38.1%
2026-01-20 07:40:54,693 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 547.9 tokens/s, Avg generation throughput: 36.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.8%, Prefix cache hit rate: 38.0%
2026-01-20 07:41:04,694 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 428.0 tokens/s, Avg generation throughput: 67.1 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 22.0%, Prefix cache hit rate: 37.9%
2026-01-20 07:41:14,694 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 691.3 tokens/s, Avg generation throughput: 70.6 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 30.0%, Prefix cache hit rate: 37.8%
2026-01-20 07:41:24,694 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 832.6 tokens/s, Avg generation throughput: 77.6 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 34.5%, Prefix cache hit rate: 37.7%
2026-01-20 07:41:34,694 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 716.8 tokens/s, Avg generation throughput: 73.7 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 40.9%, Prefix cache hit rate: 37.6%
2026-01-20 07:41:44,695 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 323.6 tokens/s, Avg generation throughput: 105.3 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 31.9%, Prefix cache hit rate: 37.5%
2026-01-20 07:41:54,696 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 644.3 tokens/s, Avg generation throughput: 73.2 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 35.6%, Prefix cache hit rate: 37.4%
2026-01-20 07:42:04,696 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 472.3 tokens/s, Avg generation throughput: 57.7 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 28.9%, Prefix cache hit rate: 37.3%
2026-01-20 07:42:14,696 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 579.7 tokens/s, Avg generation throughput: 57.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 32.5%, Prefix cache hit rate: 37.2%
2026-01-20 07:42:24,696 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 195.7 tokens/s, Avg generation throughput: 69.8 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 20.8%, Prefix cache hit rate: 37.2%
2026-01-20 07:42:34,696 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 578.2 tokens/s, Avg generation throughput: 88.2 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 37.2%, Prefix cache hit rate: 37.1%
2026-01-20 07:42:44,696 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 178.5 tokens/s, Avg generation throughput: 112.4 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 27.6%, Prefix cache hit rate: 37.0%
2026-01-20 07:42:54,698 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 683.8 tokens/s, Avg generation throughput: 95.3 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 33.9%, Prefix cache hit rate: 36.9%
2026-01-20 07:43:04,698 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 176.6 tokens/s, Avg generation throughput: 76.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 5.0%, Prefix cache hit rate: 36.9%
2026-01-20 07:43:14,699 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 24.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 36.9%
2026-01-20 07:43:24,699 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 439.4 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 11.6%, Prefix cache hit rate: 36.8%
2026-01-20 07:43:34,700 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 518.2 tokens/s, Avg generation throughput: 62.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 13.6%, Prefix cache hit rate: 36.7%
2026-01-20 07:43:44,700 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 450.7 tokens/s, Avg generation throughput: 72.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 26.5%, Prefix cache hit rate: 36.6%
2026-01-20 07:43:54,701 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 52.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 12.9%, Prefix cache hit rate: 36.6%
2026-01-20 07:44:04,701 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.7 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 36.6%
2026-01-20 07:44:14,701 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1259.7 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 31.9%, Prefix cache hit rate: 36.4%
2026-01-20 07:44:24,701 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 186.8 tokens/s, Avg generation throughput: 72.1 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 23.7%, Prefix cache hit rate: 36.4%
2026-01-20 07:44:34,701 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 45.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 5.9%, Prefix cache hit rate: 36.4%
2026-01-20 07:44:44,701 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 833.1 tokens/s, Avg generation throughput: 68.4 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 17.8%, Prefix cache hit rate: 36.2%
2026-01-20 07:44:54,702 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 648.2 tokens/s, Avg generation throughput: 61.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 28.2%, Prefix cache hit rate: 36.1%
2026-01-20 07:45:04,702 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 75.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 30.0%, Prefix cache hit rate: 36.1%
2026-01-20 07:45:14,702 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 133.6 tokens/s, Avg generation throughput: 88.5 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 4.2%, Prefix cache hit rate: 36.0%
2026-01-20 07:45:24,702 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 716.8 tokens/s, Avg generation throughput: 80.6 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 23.9%, Prefix cache hit rate: 35.9%
2026-01-20 07:45:34,702 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 716.8 tokens/s, Avg generation throughput: 113.1 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 40.9%, Prefix cache hit rate: 35.8%
2026-01-20 07:45:44,703 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 520.0 tokens/s, Avg generation throughput: 119.2 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 52.2%, Prefix cache hit rate: 35.7%
2026-01-20 07:45:54,703 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 201.7 tokens/s, Avg generation throughput: 126.5 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 20.6%, Prefix cache hit rate: 35.6%
2026-01-20 07:46:04,704 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 205.6 tokens/s, Avg generation throughput: 86.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 5.6%, Prefix cache hit rate: 35.6%
2026-01-20 07:46:14,705 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 424.5 tokens/s, Avg generation throughput: 53.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 6.5%, Prefix cache hit rate: 35.5%
2026-01-20 07:46:24,705 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 954.4 tokens/s, Avg generation throughput: 76.5 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 13.4%, Prefix cache hit rate: 35.4%
2026-01-20 07:46:34,705 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 617.9 tokens/s, Avg generation throughput: 54.2 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 22.6%, Prefix cache hit rate: 35.3%
2026-01-20 07:46:44,705 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 233.1 tokens/s, Avg generation throughput: 100.1 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 30.9%, Prefix cache hit rate: 35.2%
2026-01-20 07:46:54,706 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 623.4 tokens/s, Avg generation throughput: 117.3 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 41.2%, Prefix cache hit rate: 35.1%
2026-01-20 07:47:04,707 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 371.1 tokens/s, Avg generation throughput: 89.4 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 20.4%, Prefix cache hit rate: 35.0%
2026-01-20 07:47:14,707 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 347.8 tokens/s, Avg generation throughput: 68.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 19.7%, Prefix cache hit rate: 34.9%
2026-01-20 07:47:24,707 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 11.4%, Prefix cache hit rate: 34.9%
2026-01-20 07:47:34,707 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 34.9%
2026-01-20 07:47:44,708 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1017.9 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 26.1%, Prefix cache hit rate: 34.8%
2026-01-20 07:47:54,708 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 562.7 tokens/s, Avg generation throughput: 91.0 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 42.2%, Prefix cache hit rate: 34.7%
2026-01-20 07:48:04,708 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 517.0 tokens/s, Avg generation throughput: 104.8 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 29.1%, Prefix cache hit rate: 34.6%
2026-01-20 07:48:14,708 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 624.3 tokens/s, Avg generation throughput: 103.9 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 20.3%, Prefix cache hit rate: 34.4%
2026-01-20 07:48:24,708 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 130.3 tokens/s, Avg generation throughput: 121.9 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 21.5%, Prefix cache hit rate: 34.4%
2026-01-20 07:48:34,708 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 908.5 tokens/s, Avg generation throughput: 103.5 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 36.6%, Prefix cache hit rate: 34.3%
2026-01-20 07:48:44,708 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 275.5 tokens/s, Avg generation throughput: 140.3 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 32.1%, Prefix cache hit rate: 34.2%
2026-01-20 07:48:54,709 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 502.6 tokens/s, Avg generation throughput: 121.3 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 41.5%, Prefix cache hit rate: 34.1%
2026-01-20 07:49:04,709 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 84.6 tokens/s, Avg generation throughput: 133.5 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 26.8%, Prefix cache hit rate: 34.0%
2026-01-20 07:49:14,709 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1084.0 tokens/s, Avg generation throughput: 137.7 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 44.5%, Prefix cache hit rate: 33.9%
2026-01-20 07:49:24,710 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 185.3 tokens/s, Avg generation throughput: 116.1 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 23.9%, Prefix cache hit rate: 33.8%
2026-01-20 07:49:34,711 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 432.3 tokens/s, Avg generation throughput: 120.2 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 37.5%, Prefix cache hit rate: 33.7%
2026-01-20 07:49:44,712 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 799.1 tokens/s, Avg generation throughput: 141.4 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 33.9%, Prefix cache hit rate: 33.6%
2026-01-20 07:49:54,713 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 332.9 tokens/s, Avg generation throughput: 153.7 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 40.5%, Prefix cache hit rate: 33.5%
2026-01-20 07:50:04,713 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 702.8 tokens/s, Avg generation throughput: 153.8 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 51.3%, Prefix cache hit rate: 33.4%
2026-01-20 07:50:14,714 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 92.8 tokens/s, Avg generation throughput: 158.7 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 33.0%, Prefix cache hit rate: 33.3%
2026-01-20 07:50:24,715 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 58.4 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 33.3%
2026-01-20 07:50:34,716 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 144.1 tokens/s, Avg generation throughput: 11.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.9%, Prefix cache hit rate: 33.3%
2026-01-20 07:50:44,716 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 649.5 tokens/s, Avg generation throughput: 69.1 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 21.6%, Prefix cache hit rate: 33.2%
2026-01-20 07:50:54,716 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 609.7 tokens/s, Avg generation throughput: 130.5 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 39.8%, Prefix cache hit rate: 33.0%
2026-01-20 07:51:04,716 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 299.3 tokens/s, Avg generation throughput: 162.6 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 36.2%, Prefix cache hit rate: 33.0%
2026-01-20 07:51:14,716 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 724.6 tokens/s, Avg generation throughput: 174.0 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 46.9%, Prefix cache hit rate: 32.9%
2026-01-20 07:51:24,716 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 953.7 tokens/s, Avg generation throughput: 176.2 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 54.6%, Prefix cache hit rate: 32.7%
2026-01-20 07:51:34,717 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 874.8 tokens/s, Avg generation throughput: 145.8 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 32.9%, Prefix cache hit rate: 32.6%
2026-01-20 07:51:44,717 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1021.8 tokens/s, Avg generation throughput: 93.0 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 52.4%, Prefix cache hit rate: 32.4%
2026-01-20 07:51:54,717 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 232.8 tokens/s, Avg generation throughput: 79.6 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 18.2%, Prefix cache hit rate: 32.4%
2026-01-20 07:52:04,718 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1337.5 tokens/s, Avg generation throughput: 109.5 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 53.9%, Prefix cache hit rate: 32.2%
2026-01-20 07:52:14,718 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 834.2 tokens/s, Avg generation throughput: 116.1 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 40.5%, Prefix cache hit rate: 32.1%
2026-01-20 07:52:24,718 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 853.7 tokens/s, Avg generation throughput: 132.3 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 64.8%, Prefix cache hit rate: 32.0%
2026-01-20 07:52:34,718 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 745.7 tokens/s, Avg generation throughput: 170.7 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 48.6%, Prefix cache hit rate: 31.9%
2026-01-20 07:52:44,718 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 153.3 tokens/s, Avg generation throughput: 75.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 4.3%, Prefix cache hit rate: 31.9%
2026-01-20 07:52:54,718 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 229.5 tokens/s, Avg generation throughput: 64.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 5.2%, Prefix cache hit rate: 31.9%
2026-01-20 07:53:04,718 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 6.2%, Prefix cache hit rate: 31.9%
2026-01-20 07:53:14,719 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 133.5 tokens/s, Avg generation throughput: 13.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.5%, Prefix cache hit rate: 31.8%
2026-01-20 07:53:24,719 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1202.9 tokens/s, Avg generation throughput: 62.7 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 34.7%, Prefix cache hit rate: 31.7%
2026-01-20 07:53:34,720 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1015.1 tokens/s, Avg generation throughput: 116.2 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 47.2%, Prefix cache hit rate: 31.6%
2026-01-20 07:53:44,720 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 918.6 tokens/s, Avg generation throughput: 138.7 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 33.0%, Prefix cache hit rate: 31.5%
2026-01-20 07:53:54,720 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 756.6 tokens/s, Avg generation throughput: 112.8 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 47.8%, Prefix cache hit rate: 31.4%
2026-01-20 07:54:04,721 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 588.7 tokens/s, Avg generation throughput: 166.5 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 55.4%, Prefix cache hit rate: 31.4%
2026-01-20 07:54:14,721 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 840.3 tokens/s, Avg generation throughput: 152.7 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 52.8%, Prefix cache hit rate: 31.3%
2026-01-20 07:54:24,721 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1244.9 tokens/s, Avg generation throughput: 160.8 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 63.1%, Prefix cache hit rate: 31.2%
2026-01-20 07:54:34,722 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 230.6 tokens/s, Avg generation throughput: 195.5 tokens/s, Running: 6 reqs, Waiting: 0 reqs, GPU KV cache usage: 65.2%, Prefix cache hit rate: 31.1%
2026-01-20 07:54:44,723 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1042.5 tokens/s, Avg generation throughput: 186.1 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 51.3%, Prefix cache hit rate: 31.0%
2026-01-20 07:54:54,723 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 512.7 tokens/s, Avg generation throughput: 151.6 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 31.3%, Prefix cache hit rate: 30.9%
2026-01-20 07:55:04,723 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 154.3 tokens/s, Avg generation throughput: 80.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 10.6%, Prefix cache hit rate: 30.9%
2026-01-20 07:55:14,723 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 791.9 tokens/s, Avg generation throughput: 54.1 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 14.0%, Prefix cache hit rate: 30.8%
2026-01-20 07:55:24,723 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 52.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.5%, Prefix cache hit rate: 30.8%
2026-01-20 07:55:34,723 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 4.4%, Prefix cache hit rate: 30.8%
2026-01-20 07:55:44,723 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 30.8%
2026-01-20 07:55:54,724 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1254.6 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 32.0%, Prefix cache hit rate: 30.7%
2026-01-20 07:56:04,725 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 936.8 tokens/s, Avg generation throughput: 118.9 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 38.9%, Prefix cache hit rate: 30.6%
2026-01-20 07:56:14,726 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 669.6 tokens/s, Avg generation throughput: 167.3 tokens/s, Running: 6 reqs, Waiting: 0 reqs, GPU KV cache usage: 59.6%, Prefix cache hit rate: 30.5%
2026-01-20 07:56:24,727 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 581.8 tokens/s, Avg generation throughput: 169.1 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 34.3%, Prefix cache hit rate: 30.4%
2026-01-20 07:56:34,727 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 804.6 tokens/s, Avg generation throughput: 152.1 tokens/s, Running: 6 reqs, Waiting: 0 reqs, GPU KV cache usage: 52.6%, Prefix cache hit rate: 30.3%
2026-01-20 07:56:44,727 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1357.3 tokens/s, Avg generation throughput: 202.8 tokens/s, Running: 6 reqs, Waiting: 0 reqs, GPU KV cache usage: 59.3%, Prefix cache hit rate: 30.2%
2026-01-20 07:56:54,728 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1249.7 tokens/s, Avg generation throughput: 189.9 tokens/s, Running: 6 reqs, Waiting: 0 reqs, GPU KV cache usage: 75.5%, Prefix cache hit rate: 30.1%
2026-01-20 07:57:04,729 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 383.6 tokens/s, Avg generation throughput: 188.3 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 47.8%, Prefix cache hit rate: 30.0%
2026-01-20 07:57:14,729 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1044.9 tokens/s, Avg generation throughput: 170.7 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 30.2%, Prefix cache hit rate: 29.9%
2026-01-20 07:57:24,729 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 186.8 tokens/s, Avg generation throughput: 161.3 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 21.5%, Prefix cache hit rate: 29.8%
2026-01-20 07:57:34,729 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 447.6 tokens/s, Avg generation throughput: 126.6 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.7%, Prefix cache hit rate: 29.8%
2026-01-20 07:57:44,730 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 53.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 7.1%, Prefix cache hit rate: 29.8%
2026-01-20 07:57:54,730 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 362.0 tokens/s, Avg generation throughput: 15.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.3%, Prefix cache hit rate: 29.7%
2026-01-20 07:58:04,731 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1520.3 tokens/s, Avg generation throughput: 81.1 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 30.6%, Prefix cache hit rate: 29.6%
2026-01-20 07:58:14,731 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1205.0 tokens/s, Avg generation throughput: 129.7 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 63.5%, Prefix cache hit rate: 29.5%
2026-01-20 07:58:24,732 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1179.3 tokens/s, Avg generation throughput: 206.3 tokens/s, Running: 7 reqs, Waiting: 0 reqs, GPU KV cache usage: 86.3%, Prefix cache hit rate: 29.3%
2026-01-20 07:58:34,732 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 845.4 tokens/s, Avg generation throughput: 198.1 tokens/s, Running: 7 reqs, Waiting: 0 reqs, GPU KV cache usage: 70.1%, Prefix cache hit rate: 29.2%
2026-01-20 07:58:44,732 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 904.6 tokens/s, Avg generation throughput: 211.6 tokens/s, Running: 6 reqs, Waiting: 0 reqs, GPU KV cache usage: 59.0%, Prefix cache hit rate: 29.1%
2026-01-20 07:58:54,733 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 898.1 tokens/s, Avg generation throughput: 217.3 tokens/s, Running: 6 reqs, Waiting: 0 reqs, GPU KV cache usage: 50.6%, Prefix cache hit rate: 29.0%
2026-01-20 07:59:04,734 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1433.4 tokens/s, Avg generation throughput: 176.3 tokens/s, Running: 6 reqs, Waiting: 0 reqs, GPU KV cache usage: 70.7%, Prefix cache hit rate: 28.8%
2026-01-20 07:59:14,734 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 758.7 tokens/s, Avg generation throughput: 214.1 tokens/s, Running: 7 reqs, Waiting: 0 reqs, GPU KV cache usage: 85.0%, Prefix cache hit rate: 28.7%
2026-01-20 07:59:24,734 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1162.6 tokens/s, Avg generation throughput: 191.1 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 62.0%, Prefix cache hit rate: 29.5%
2026-01-20 07:59:34,734 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 55.3 tokens/s, Avg generation throughput: 147.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.0%, Prefix cache hit rate: 29.4%
2026-01-20 07:59:44,735 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 76.2 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 17.9%, Prefix cache hit rate: 29.4%
2026-01-20 07:59:54,735 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 37.2 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 29.4%
2026-01-20 08:00:04,736 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 498.7 tokens/s, Avg generation throughput: 27.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.2%, Prefix cache hit rate: 29.4%
2026-01-20 08:00:14,736 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1241.4 tokens/s, Avg generation throughput: 73.3 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 27.8%, Prefix cache hit rate: 29.2%
2026-01-20 08:00:24,736 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 898.8 tokens/s, Avg generation throughput: 145.0 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 45.0%, Prefix cache hit rate: 29.1%
2026-01-20 08:00:34,736 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1159.3 tokens/s, Avg generation throughput: 126.6 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 46.1%, Prefix cache hit rate: 28.9%
2026-01-20 08:00:44,737 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 949.3 tokens/s, Avg generation throughput: 123.0 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 47.6%, Prefix cache hit rate: 28.8%
2026-01-20 08:00:54,738 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1268.2 tokens/s, Avg generation throughput: 168.9 tokens/s, Running: 6 reqs, Waiting: 0 reqs, GPU KV cache usage: 69.5%, Prefix cache hit rate: 28.7%
2026-01-20 08:01:04,739 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1492.8 tokens/s, Avg generation throughput: 210.5 tokens/s, Running: 7 reqs, Waiting: 0 reqs, GPU KV cache usage: 90.1%, Prefix cache hit rate: 28.5%
2026-01-20 08:01:14,739 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 812.0 tokens/s, Avg generation throughput: 209.7 tokens/s, Running: 6 reqs, Waiting: 0 reqs, GPU KV cache usage: 65.5%, Prefix cache hit rate: 28.4%
2026-01-20 08:01:24,739 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 684.2 tokens/s, Avg generation throughput: 197.6 tokens/s, Running: 7 reqs, Waiting: 0 reqs, GPU KV cache usage: 81.3%, Prefix cache hit rate: 28.3%
2026-01-20 08:01:34,740 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 716.8 tokens/s, Avg generation throughput: 174.2 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 22.6%, Prefix cache hit rate: 28.3%
2026-01-20 08:01:44,741 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 44.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 19.5%, Prefix cache hit rate: 28.3%
2026-01-20 08:01:54,741 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 23.8 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 28.3%
2026-01-20 08:02:04,741 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 765.5 tokens/s, Avg generation throughput: 25.4 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 19.5%, Prefix cache hit rate: 28.2%
2026-01-20 08:02:14,741 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 629.7 tokens/s, Avg generation throughput: 76.8 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 28.9%, Prefix cache hit rate: 28.1%
2026-01-20 08:02:24,741 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 718.2 tokens/s, Avg generation throughput: 92.2 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 36.2%, Prefix cache hit rate: 28.0%
2026-01-20 08:02:34,741 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1826.6 tokens/s, Avg generation throughput: 119.6 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 56.1%, Prefix cache hit rate: 27.8%
2026-01-20 08:02:44,742 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 886.8 tokens/s, Avg generation throughput: 119.9 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 42.0%, Prefix cache hit rate: 27.7%
2026-01-20 08:02:54,742 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 474.6 tokens/s, Avg generation throughput: 154.4 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 48.7%, Prefix cache hit rate: 27.6%
2026-01-20 08:03:04,743 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1081.1 tokens/s, Avg generation throughput: 166.6 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 48.0%, Prefix cache hit rate: 27.5%
2026-01-20 08:03:14,744 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 1214.1 tokens/s, Avg generation throughput: 185.7 tokens/s, Running: 7 reqs, Waiting: 0 reqs, GPU KV cache usage: 71.5%, Prefix cache hit rate: 27.3%
2026-01-20 08:03:24,744 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 433.6 tokens/s, Avg generation throughput: 192.7 tokens/s, Running: 5 reqs, Waiting: 0 reqs, GPU KV cache usage: 51.0%, Prefix cache hit rate: 27.3%
2026-01-20 08:03:34,745 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 132.2 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 29.5%, Prefix cache hit rate: 27.3%
2026-01-20 08:03:44,746 INFO vllm.v1.metrics.loggers: Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 26.1 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 27.3%
2026-01-20 08:03:48,505 INFO vllm.entrypoints.launcher: Shutting down FastAPI HTTP server.
